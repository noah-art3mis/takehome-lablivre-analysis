{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad06a299",
   "metadata": {},
   "source": [
    "# Análise de projetos de infraestrutura com investimento federal no Distrito Federal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d584d537",
   "metadata": {},
   "source": [
    "Teste avaliativo para vaga de bolsista em engenharia/análise de dados (LabLivre). Ver [material de referência](https://docs.google.com/document/d/1WWBnAodJoDo40WZ6ysI5cGx90KFYAp7GTFLrWPjmMFE/edit?tab=t.0)\n",
    "\n",
    "Fonte de dados: [obrasgov](https://api.obrasgov.gestao.gov.br/obrasgov/api/swagger-ui/index.html#/Projeto%20De%20Investimento/buscarPorFiltro)\n",
    "\n",
    "Relatório detalhado de tratamento de dados com visualizações. Para análises acessíveis ver a conclusão. Em resumo:\n",
    "\n",
    "-   ... TODO\n",
    "\n",
    "-   TOC\n",
    "\n",
    "Observação: IA (Cursor) foi usado para a produção deste relatório, principalmente para agilizar a produção de gráficos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "77a0fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "import glob\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "import pingouin as pg\n",
    "import statsmodels.api as sm\n",
    "import hdbscan\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# cores do lablivre\n",
    "palette = [\"#412355\", \"#F2701C\", \"#18CEE6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bdec96",
   "metadata": {},
   "source": [
    "## 1. Extração dos dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "699d4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script de coleta de dados foi executado separadamente\n",
    "\n",
    "\n",
    "def get_data(page: int) -> dict:\n",
    "    url = \"https://api.obrasgov.gestao.gov.br/obrasgov/api/projeto-investimento\"\n",
    "    params = {\"uf\": \"DF\", \"pagina\": page, \"tamanhoDaPagina\": 100}\n",
    "    headers = {\"accept\": \"*/*\"}\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to get data: {response.status_code}\")\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # inelegante mas eficiente. certamente não tem 10000 itens\n",
    "    for page in range(100):\n",
    "        response = get_data(page)\n",
    "        print(f\"Page {page} processed\")\n",
    "\n",
    "        # salvar dados brutos primeiro para não depender da api caso ocorram problemas\n",
    "        with open(f\"data/data-{page}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(response[\"content\"], f, indent=4)\n",
    "        print(f\"Data saved to data/data-{page}.json\")\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        page += 1\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bc68ee",
   "metadata": {},
   "source": [
    "## 2. Tratamento de dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "287c3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_files() -> list[dict]:\n",
    "    json_files = glob.glob(\"data/data-*.json\")\n",
    "    all_records = []\n",
    "\n",
    "    for file in json_files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            records = json.load(f)\n",
    "            all_records.extend(records)\n",
    "\n",
    "    return all_records\n",
    "\n",
    "\n",
    "df = pd.DataFrame(load_json_files())\n",
    "\n",
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "a0a93b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_cols = [\n",
    "    \"tomadores\",\n",
    "    \"executores\",\n",
    "    \"repassadores\",\n",
    "    \"eixos\",\n",
    "    \"tipos\",\n",
    "    \"subTipos\",\n",
    "    \"fontesDeRecurso\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf345ab0",
   "metadata": {},
   "source": [
    "### 2.1 Duplicatas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "9690b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyse_duplicates import check_duplicates, analyze_false_duplicates\n",
    "\n",
    "# existem duplicatas que só diferem no conteúdo das listas. não quero entediar você com esse código gerado por IA então movi para outro arquivo\n",
    "\n",
    "check_duplicates(df)\n",
    "analyze_false_duplicates(df, \"results/duplicate_records_report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "bb2d3f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# após investigação detalhada, todas as 'falsas duplicatas' se parecem com isso:\n",
    "\n",
    "# Linha 133: [{'id': 90, 'descricao': 'Preservação do Patrimônio', 'idTipo': 5}] (5 = Administrativo)\n",
    "# Linha 491: [{'id': 90, 'descricao': 'Preservação do Patrimônio', 'idTipo': 43}] (43 = Cultura)\n",
    "\n",
    "# para mais exemplos, consulte o relatório (`results/duplicate_records_report.txt`).\n",
    "# não tenho certeza do motivo disso; talvez os rótulos sejam ambíguos para as pessoas que preenchem algum formulário.\n",
    "# mas isso parece indicar que são, de fato, duplicatas. então serão removidas.\n",
    "\n",
    "df.duplicated(subset=[\"idUnico\"]).sum()\n",
    "df.drop_duplicates(subset=[\"idUnico\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "55bc8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8fdbbc",
   "metadata": {},
   "source": [
    "### 2.2 Valores ausentes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "6403e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover ceps preenchidos com 1 ou espaço.\n",
    "df[\"cep\"] = df[\"cep\"].str.replace(r\"^1$\", \"\", regex=True)\n",
    "df[\"cep\"] = df[\"cep\"].str.replace(r\"\\s+\", \"\", regex=True).replace(\"\", None)\n",
    "df[\"cep\"] = df[\"cep\"].str.replace(\"-\", \"\")\n",
    "df[\"cep\"] = df[\"cep\"].str.replace(\".\", \"\")\n",
    "\n",
    "# remover ceps com menos de 8 dígitos\n",
    "df[\"cep\"] = df[\"cep\"].apply(lambda x: None if pd.isna(x) or len(str(x)) < 8 else x)\n",
    "\n",
    "df[\"cep\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "605c3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover enderecos preenchidos com 1 ou espaço.\n",
    "df[\"endereco\"] = df[\"endereco\"].str.strip()\n",
    "df[\"endereco\"] = df[\"endereco\"].str.replace(r\"^1$\", \"\", regex=True)\n",
    "df[\"endereco\"] = df[\"endereco\"].str.replace(r\"^\\s+$\", \"\", regex=True).replace(\"\", None)\n",
    "df[\"endereco\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "63fc8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = df.drop(columns=nested_cols, axis=1)\n",
    "info_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Unique Values\": object_cols.nunique(),\n",
    "        \"% Unique\": (object_cols.nunique() / object_cols.count() * 100).round(1),\n",
    "        \"NaN Values\": object_cols.isna().sum(),\n",
    "        \"% NaN\": (object_cols.isna().sum() / len(object_cols) * 100).round(1),\n",
    "    }\n",
    ")\n",
    "info_df[info_df[\"% NaN\"] > 1].sort_values(by=\"% NaN\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4b113",
   "metadata": {},
   "source": [
    "Há muitos valores ausentes. Não entendo o motivo disso, mas não me parece um erro. Muitos desses são datas que suspeito serem futuras, ou campos do tipo 'outras observações'. Mais notável é a ausência de `qdtEmpregosGerados`, `populacaoBeneficiada`, `cep` e `endereco`. Não tiraria conclusões precipitadas sem saber mais.\n",
    "\n",
    "Também não vejo necessidade de fazer imputação aqui. Então todos permanecem como estão.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834b9163",
   "metadata": {},
   "source": [
    "### 2.3 Tipagem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "2000f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar isso em cada coluna para verificar o tipo da variável\n",
    "df[\"isModeladaPorBim\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "f09d6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isModeladaPorBim\"] = df[\"isModeladaPorBim\"].astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "3126c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis categoricas\n",
    "df[\"natureza\"] = df[\"natureza\"].astype(\"category\")\n",
    "df[\"situacao\"] = df[\"situacao\"].astype(\"category\")\n",
    "df[\"especie\"] = df[\"especie\"].astype(\"category\")\n",
    "df[\"uf\"] = df[\"uf\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "89607252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis de data\n",
    "# verifiquei manualmente os registros para erros de formatação mas não encontrei problemas\n",
    "\n",
    "date_cols = [\n",
    "    \"dataInicialPrevista\",\n",
    "    \"dataFinalPrevista\",\n",
    "    \"dataInicialEfetiva\",\n",
    "    \"dataFinalEfetiva\",\n",
    "    \"dataCadastro\",\n",
    "    \"dataSituacao\",\n",
    "]\n",
    "\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "f4572706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alguns registros tem strings em vez de ints. esses registros também têm outros problemas; veja abaixo.\n",
    "# isso coage strings para null\n",
    "# converte para float em vez de int para permitir valores nulos\n",
    "df[\"qdtEmpregosGerados\"] = pd.to_numeric(df[\"qdtEmpregosGerados\"], errors=\"coerce\")\n",
    "df[\"populacaoBeneficiada\"] = pd.to_numeric(df[\"populacaoBeneficiada\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "cdb5be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60058ca9",
   "metadata": {},
   "source": [
    "### 2.4 Colunas aninhadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "c13c32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_nested_column(\n",
    "    df: pd.DataFrame, id_col: str, nested_col: str\n",
    ") -> pd.DataFrame:\n",
    "    def convert_dict_values_to_str(x):\n",
    "        # pd.json_normalize(df['tomadores'].explode()) converte o id para float, o que pode causar problemas devido à imprecisão de ponto flutuante mesmo se convertido de volta para int/str. por isso, preciso converter os valores para strings primeiro, o que requer um código um pouco confuso:\n",
    "\n",
    "        if not isinstance(x, list):\n",
    "            return x\n",
    "        return [{key: str(value) for key, value in item.items()} for item in x]\n",
    "\n",
    "    df[nested_col] = df[nested_col].apply(convert_dict_values_to_str)\n",
    "    exploded = df[[id_col, nested_col]].explode(nested_col)\n",
    "    exploded = exploded.dropna(subset=[nested_col])\n",
    "    normalized = pd.json_normalize(exploded[nested_col])\n",
    "    normalized[id_col] = exploded[id_col].values\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def create_entity_table_from_junction_table(\n",
    "    old_df: pd.DataFrame, prev_index: str, actual_index: str\n",
    ") -> pd.DataFrame:\n",
    "    new_df = old_df.dropna(subset=[prev_index])\n",
    "    new_df.drop_duplicates(subset=[actual_index], inplace=True)\n",
    "    new_df.set_index(actual_index, inplace=True)\n",
    "    new_df.drop(prev_index, axis=1, inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "1a6a05d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuni essas tabelas em uma só, pois são todas referentes a instituicoes e usam o mesmo sistema de códigos.\n",
    "\n",
    "projeto_tomadores_df = normalize_nested_column(df, \"idUnico\", \"tomadores\")\n",
    "projeto_executores_df = normalize_nested_column(df, \"idUnico\", \"executores\")\n",
    "projeto_repassadores_df = normalize_nested_column(df, \"idUnico\", \"repassadores\")\n",
    "\n",
    "tomadores_df = create_entity_table_from_junction_table(\n",
    "    projeto_tomadores_df, \"idUnico\", \"codigo\"\n",
    ")\n",
    "executores_df = create_entity_table_from_junction_table(\n",
    "    projeto_executores_df, \"idUnico\", \"codigo\"\n",
    ")\n",
    "repassadores_df = create_entity_table_from_junction_table(\n",
    "    projeto_repassadores_df, \"idUnico\", \"codigo\"\n",
    ")\n",
    "\n",
    "instituicoes_df = pd.concat([tomadores_df, executores_df, repassadores_df])\n",
    "\n",
    "# deduplicate indices\n",
    "instituicoes_df = instituicoes_df.loc[~instituicoes_df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "instituicoes_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "e6526721",
   "metadata": {},
   "outputs": [],
   "source": [
    "projeto_eixos_df = normalize_nested_column(df, \"idUnico\", \"eixos\")\n",
    "\n",
    "eixos_df = create_entity_table_from_junction_table(projeto_eixos_df, \"idUnico\", \"id\")\n",
    "\n",
    "eixos_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "f584f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "projeto_tipos_df = normalize_nested_column(df, \"idUnico\", \"tipos\")\n",
    "\n",
    "tipos_df = create_entity_table_from_junction_table(projeto_tipos_df, \"idUnico\", \"id\")\n",
    "\n",
    "tipos_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "2e64d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "projeto_subtipos_df = normalize_nested_column(df, \"idUnico\", \"subTipos\")\n",
    "\n",
    "subtipos_df = create_entity_table_from_junction_table(\n",
    "    projeto_subtipos_df, \"idUnico\", \"id\"\n",
    ")\n",
    "\n",
    "subtipos_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "2e00736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nesse caso é one to many e nao many to many, entao nao precisa da tabela intermediaria. mas reutiliza o codigo de qualquer forma\n",
    "\n",
    "fontes_de_recurso_df = normalize_nested_column(\n",
    "    df, \"idUnico\", \"fontesDeRecurso\"\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# nesse caso estava certo o float\n",
    "fontes_de_recurso_df[\"valorInvestimentoPrevisto\"] = pd.to_numeric(\n",
    "    fontes_de_recurso_df[\"valorInvestimentoPrevisto\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "fontes_de_recurso_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "55f21226",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=nested_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8c908c",
   "metadata": {},
   "source": [
    "### 2.X Limpeza de dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c826461",
   "metadata": {},
   "source": [
    "#### Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "e3caa064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erro de encoding. todos parecem seguir nomes parecidos, indicando que o erro deve ser relacionado à fonte. endereço são rodovias.\n",
    "# Texto em UTF-8, foi lido como Latin-1 (ISO-8859-1)\n",
    "enconding_issue = df[df[\"descricao\"].str.contains(\"Ã§Ã\")]\n",
    "print(f\"Pelo menos {enconding_issue.shape[0]} projetos com erro de encoding\")\n",
    "df[df[\"descricao\"].str.contains(\"Ã§Ã\")].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "2b01cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_encoding(item: any) -> any:\n",
    "    if isinstance(item, str):\n",
    "        try:\n",
    "            return item.encode(\"latin-1\").decode(\"utf-8\")\n",
    "        except:\n",
    "            return item\n",
    "    return item\n",
    "\n",
    "\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].apply(fix_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8129c2a8",
   "metadata": {},
   "source": [
    "#### Registros incorretos devido a testes de integração\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "cebb90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# há um sujeito chamado Ronald Alves Vieira e ele está testando em produção\n",
    "test_df = df[df[\"nome\"].str.contains(\"Ronald\", case=False, na=False)]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "56c34072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é possível que hajam mais casos que não encontrei\n",
    "# é possível que essa limpeza remova dados reais\n",
    "\n",
    "\n",
    "antes = df.shape[0]\n",
    "\n",
    "df = df[~df[\"nome\"].str.contains(\"Ronald\", case=False, na=False)]\n",
    "df = df[~df[\"nome\"].str.contains(\"Teste\", case=False, na=False)]\n",
    "\n",
    "depois = df.shape[0]\n",
    "\n",
    "print(\n",
    "    f\"Removidos {antes - depois} projetos por serem registros falsos (efeitos colaterais de testes de integração)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a85fc33",
   "metadata": {},
   "source": [
    "### 2.5 Carregamento de dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "56c34072",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(\"projeto_investimento.db\") as con:\n",
    "    # main\n",
    "    df.to_sql(\"projeto_investimento\", con, if_exists=\"replace\")\n",
    "\n",
    "    # entity tables\n",
    "    instituicoes_df.to_sql(\"instituicoes\", con, if_exists=\"replace\")\n",
    "    eixos_df.to_sql(\"eixos\", con, if_exists=\"replace\")\n",
    "    tipos_df.to_sql(\"tipos\", con, if_exists=\"replace\")\n",
    "    subtipos_df.to_sql(\"subtipos\", con, if_exists=\"replace\")\n",
    "    fontes_de_recurso_df.to_sql(\"fontes_de_recurso\", con, if_exists=\"replace\")\n",
    "\n",
    "    # junction tables\n",
    "    projeto_tomadores_df.to_sql(\"projeto_tomadores\", con, if_exists=\"replace\")\n",
    "    projeto_executores_df.to_sql(\"projeto_executores\", con, if_exists=\"replace\")\n",
    "    projeto_repassadores_df.to_sql(\"projeto_repassadores\", con, if_exists=\"replace\")\n",
    "    projeto_eixos_df.to_sql(\"projeto_eixos\", con, if_exists=\"replace\")\n",
    "    projeto_tipos_df.to_sql(\"projeto_tipos\", con, if_exists=\"replace\")\n",
    "    projeto_subtipos_df.to_sql(\"projeto_subtipos\", con, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "5a85fc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with sqlite3.connect(\"projeto_investimento.db\") as con:\n",
    "#     df = pd.read_sql_query(\"SELECT * FROM projeto_investimento\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69df6a4",
   "metadata": {},
   "source": [
    "### 2.5 Engenharia de características\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab44220",
   "metadata": {},
   "source": [
    "Criação de novas colunas para fins de análise\n",
    "\n",
    "-   `textoTotal`: concatenação de dados textuais de um registro para processamento de linguagem natural (NLP)\n",
    "-   `investimentoTotal`: consolidação de `fontesDeRecurso` para análise quantitativa\n",
    "-   `investimentoFaixa`: versão categórica de `investimentoTotal` por faixas (por exemplo, de 100 a 1000, de 1,000 a 10,000, etc.)\n",
    "-   `isInvestimentoSimbolico`: investimentos com valores menores que 1 real; assume-se que possuem valor simbólico\n",
    "-   `duracaoPrevista`: calcular duração prevista de projetos (via `dataInicialPrevista`, `dataFinalPrevista`)\n",
    "-   `lat`, `lon`: obtenção de dados geográficos (via `cep`) usando geocoding para visualização gráfica\n",
    "-   calcular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "57801c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# textoTotal\n",
    "\n",
    "text_cols = [\n",
    "    \"nome\",\n",
    "    \"endereco\",\n",
    "    \"descricao\",\n",
    "    \"funcaoSocial\",\n",
    "    \"metaGlobal\",\n",
    "    \"especie\",\n",
    "    \"natureza\",\n",
    "    \"naturezaOutras\",\n",
    "    \"situacao\",\n",
    "    \"descPlanoNacionalPoliticaVinculado\",\n",
    "    \"descPopulacaoBeneficiada\",\n",
    "    \"observacoesPertinentes\",\n",
    "]\n",
    "\n",
    "\n",
    "def make_text_total(row):\n",
    "    text_total = []\n",
    "    for x in row:\n",
    "        if pd.notna(x):\n",
    "            text_total.append(str(x))\n",
    "    return \"\\n\\n\".join(text_total)\n",
    "\n",
    "\n",
    "df[\"textoTotal\"] = df[text_cols].apply(make_text_total, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df[\"textoTotal\"].str.len(), bins=30)\n",
    "plt.title(\"Distribution of Text Lengths\")\n",
    "plt.xlabel(\"Number of Characters\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "eb7555d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investimentoTotal\n",
    "\n",
    "valor_por_id = (\n",
    "    fontes_de_recurso_df.groupby(\"idUnico\")[\"valorInvestimentoPrevisto\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "valor_por_id.rename(\n",
    "    columns={\"valorInvestimentoPrevisto\": \"investimentoTotal\"}, inplace=True\n",
    ")\n",
    "\n",
    "df = df.merge(valor_por_id, on=\"idUnico\", how=\"left\", validate=\"one_to_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "eb7555d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investimentoFaixa\n",
    "\n",
    "bins = [\n",
    "    0,\n",
    "    1,\n",
    "    10,\n",
    "    100,\n",
    "    1_000,\n",
    "    10_000,\n",
    "    100_000,\n",
    "    1_000_000,\n",
    "    10_000_000,\n",
    "    100_000_000,\n",
    "    1_000_000_000,\n",
    "    np.inf,\n",
    "]\n",
    "labels = [\n",
    "    \"<1\",\n",
    "    \"1-10\",\n",
    "    \"10-100\",\n",
    "    \"100-1k\",\n",
    "    \"1k-10k\",\n",
    "    \"10k-100k\",\n",
    "    \"100k-1M\",\n",
    "    \"1M-10M\",\n",
    "    \"10M-100M\",\n",
    "    \"100M-1B\",\n",
    "    \">1B\",\n",
    "]\n",
    "\n",
    "df[\"investimentoFaixa\"] = pd.cut(df[\"investimentoTotal\"], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "518af74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faixa_counts = df[\"investimentoFaixa\"].value_counts().reset_index()\n",
    "faixa_counts.columns = [\"investimentoFaixa\", \"count\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(\n",
    "    data=faixa_counts,\n",
    "    x=\"investimentoFaixa\",\n",
    "    y=\"count\",\n",
    "    hue=\"investimentoFaixa\",\n",
    "    palette=[palette[0] for _ in range(len(faixa_counts))],\n",
    ")\n",
    "\n",
    "# custom palette creates multiple containers\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)  # type: ignore\n",
    "\n",
    "plt.xlabel(\"Faixa de Investimento (R$)\")\n",
    "plt.ylabel(\"Projetos\")\n",
    "plt.title(\"Projetos por Faixa de Investimento\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "518af74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isInvestimentoSimbolico\n",
    "\n",
    "df[\"isInvestimentoSimbolico\"] = df[\"investimentoTotal\"] <= 1\n",
    "df[\"isInvestimentoSimbolico\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "4167d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duracaoPrevista\n",
    "df[\"duracaoPrevista\"] = df[\"dataFinalPrevista\"] - df[\"dataInicialPrevista\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "65bf64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat, lon\n",
    "\n",
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a782472f",
   "metadata": {},
   "source": [
    "## 3. Análise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344f65d",
   "metadata": {},
   "source": [
    "### 3.1 Informações básicas\n",
    "\n",
    "**Colunas:**\n",
    "\n",
    "-   **texto**\n",
    "\n",
    "    -   dados básicos: `idUnico`, `nome`, `descricao`, `funcaoSocial`, `metaGlobal`\n",
    "    -   descrições opcionais: `naturezaOutras`, `descPlanoNacionalPoliticaVinculado`, `descPopulacaoBeneficiada`, `observacoesPertinentes`\n",
    "    -   criada: `textoTotal`, `embeddings`, `cluster`\n",
    "\n",
    "-   **geográfico**\n",
    "\n",
    "    -   `cep`, `endereco`\n",
    "    -   criadas: `lat_ipedf`, `lon_ipedf`, `lat_viacep`, `lon_viacep`\n",
    "\n",
    "-   **numéricos**\n",
    "\n",
    "    -   `qdtEmpregosGerados`\n",
    "    -   `populacaoBeneficiada`\n",
    "    -   criada: `investimentoTotal`\n",
    "\n",
    "-   **datas**\n",
    "\n",
    "    -   `dataInicialPrevista`, `dataFinalPrevista`, `dataInicialEfetiva`, `dataFinalEfetiva`, `dataCadastro`, `dataSituacao`\n",
    "    -   criada: `duracaoPrevista`\n",
    "\n",
    "-   **categorias**\n",
    "\n",
    "    -   `natureza` (Estudo, Obra, Outros, Projeto, Projeto de Investimento em Infraestrutura)\n",
    "    -   `situacao` (Cadastrada, Cancelada, Concluída, Em execução, Inacabada, Inativada, Paralisada)\n",
    "    -   `especie` (Ampliação, Construção, Fabricação, Máquinas e Equipamentos, Recuperação, Reforma)\n",
    "    -   `uf` (DF)\n",
    "    -   `isModeladaPorBim` (boolean)\n",
    "    -   criada: `investimentoFaixa` (boolean)\n",
    "    -   criada: `isInvestimentoSimbolico` (boolean)\n",
    "\n",
    "-   **colunas aninhadas** (removidas após normalização)\n",
    "    -   `tomadores`, `executores`, `repassadores`, `eixos`, `tipos`, `subTipos`, `fontesDeRecurso`\n",
    "\n",
    "**Registros:** 712 (após deduplicação de 834 registros originais)\n",
    "\n",
    "**Valores ausentes mais significativos:**\n",
    "\n",
    "-   `dataFinalEfetiva`: 707 nulos (99.3%)\n",
    "-   `dataInicialEfetiva`: 690 nulos (96.9%)\n",
    "-   `qdtEmpregosGerados`: 677 nulos (95.1%)\n",
    "-   `populacaoBeneficiada`: 677 nulos (95.1%)\n",
    "-   `endereco`: 337 nulos (47.3%)\n",
    "-   `cep`: 365 nulos (51.3%)\n",
    "-   `descPlanoNacionalPoliticaVinculado`: 464 nulos (65.2%)\n",
    "-   `isModeladaPorBim`: 216 nulos (30.3%)\n",
    "\n",
    "As colunas aninhadas foram normalizadas e separadas em tabelas relacionadas no banco de dados SQLite, incluindo tabelas de entidades (instituições, eixos, tipos, subtipos, fontes de recurso) e tabelas de junção (projeto_tomadores, projeto_executores, projeto_repassadores, projeto_eixos, projeto_tipos, projeto_subtipos).\n",
    "\n",
    "Tomadores, executores e repassadores partilham do mesmo sistema de códigos e portanto estão armazenados na mesma tabela.\n",
    "\n",
    "Eixos, tipos, subtipos poderiam ser armazenados na mesma tabela com perda de normalização mas ganho em simplicidade.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd1b14b",
   "metadata": {},
   "source": [
    "### 3.2 Qualidade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8136739e",
   "metadata": {},
   "source": [
    "Em questão de anomalias, temos:\n",
    "\n",
    "1.  duplicados que diferem apenas no subtipo, como: dois registros com id 15 e mesma descrição \"Aquisição de Máquinas e Equipamentos\", mas idTipo diferentes (41 e 14).\n",
    "\n",
    "2.  organizacoes com mais de um codigo, como: \"PRESIDÊNCIA DA REPÚBLICA\" (codigo 26) e \"Presidencia da República\" (codigo 20000)\n",
    "\n",
    "3.  Vários campos (`cep`, `endereco`, `qdtEmpregosGerados`) preenchidos com um espaço em branco, dando a impressão que tem menos nulos do que realmente tem.\n",
    "\n",
    "    4.  CEPs preenchidos errado (`1` e ' ')\n",
    "    5.  125 registros similares com os mesmos problemas (' ' em vez de int em `qdtEmpregosGerados` e `populacaoBeneficiada`)\n",
    "\n",
    "4.  Registro de teste (`22312.53-84`), encontrado porque é o único com dois investimentos, os dois com valor de um centavo.\n",
    "\n",
    "5.  `descPopulacaoBeneficiada` com texto padrão\n",
    "\n",
    "6.  `descPlanoNacionalPoliticaVinculado`: alguns usuários tratam como valor categórico e outros como texto\n",
    "\n",
    "7.  `populacaoBeneficiada` alguns registros todos em maiusculo ('CONSTRUÇÃO DO NOVO IML DA PCDF')\n",
    "\n",
    "8.  alguns nomes são apenas códigos (`26.782.2087.7T98.0025`)\n",
    "\n",
    "9.  22 registros são testes e foram descartados; alguns possuem valores de investimento que poderam distorcer análises. alguns são mais obviamente testes (`40456.53-49`) do que outros (`2843.53-36`)\n",
    "\n",
    "10. 8 projetos com exatamente 50 empregos gerados sem relação aparente entre si\n",
    "\n",
    "    -   idUnico: 11486.53-40, 19176.53-10, 30067.53-80, 31923.53-48,9854.53-01, 91397.53-15, 91392.53-43, 31897.53-36.\n",
    "\n",
    "11. projetos com investimento entre 1 e 10 milhões com duração prevista de zero dias.\n",
    "\n",
    "12. `cep` preenchido com 7000000, ou com menos que 8 dígitos\n",
    "\n",
    "Sem mais informações sobre o domínio, é dificil comentar o significado dessas questões. Mas são algo a ser investigado. Possivelmente, isso indica confusão pela parte dos usuários, ou falta de adequação entre os campos do formulário e a realidade dos projetos. De qualquer forma, uma forma de reduzir isso seria incluir validação antes de salvar no banco de dados (por exemplo, recusar o CEP '1') ou transformá-los antes de inserir (por exemplo, converter o CEP ' ' para nulo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef4cf46",
   "metadata": {},
   "source": [
    "### 3.3 Descritiva\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef4cf46",
   "metadata": {},
   "source": [
    "#### 3.3.1 Variáveis categóricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "5bb57e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "a26e262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_bool = [\"#18CEE6\", \"#412355\", \"#F2701C\"]\n",
    "\n",
    "# Convert and reorder\n",
    "bim_map = {True: \"Sim\", False: \"Não\"}\n",
    "bim_counts = (\n",
    "    df[\"isModeladaPorBim\"].map(bim_map).fillna(\"Sem dados\").value_counts(dropna=False)\n",
    ")\n",
    "\n",
    "# Specify custom order\n",
    "desired_order = [\"Sim\", \"Não\", \"Sem dados\"]\n",
    "bim_counts = bim_counts.reindex(desired_order)\n",
    "percentages = bim_counts / bim_counts.sum() * 100\n",
    "\n",
    "# Create stacked bar\n",
    "fig, ax = plt.subplots(figsize=(8, 2))\n",
    "left = 0\n",
    "colors = [palette_bool[i] for i in range(len(bim_counts))]\n",
    "for i, (label, pct) in enumerate(zip(bim_counts.index, percentages)):\n",
    "    ax.barh(\n",
    "        0,\n",
    "        pct,\n",
    "        left=left,\n",
    "        color=colors[i],\n",
    "        label=f\"{label}: {bim_counts.iloc[i]} ({pct:.1f}%)\",\n",
    "    )\n",
    "    left += pct\n",
    "\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel(\"Percentage\")\n",
    "ax.set_title(\"Projeto modelado usando BIM (Building Information Modeling)\")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e262e",
   "metadata": {},
   "source": [
    "Apenas 3.5% dos projetos usou BIM, enquanto 66.2% não usou.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "01530e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_barh_plot(\n",
    "    df: pd.DataFrame,\n",
    "    column: str,\n",
    "    title: str,\n",
    "    color: str,\n",
    "    extra_space: float = 1,\n",
    "    show_percentages: bool = False,\n",
    "):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Get counts and percentages\n",
    "    value_counts = df[column].value_counts(dropna=False)\n",
    "    percentages = (value_counts / len(df)) * 100\n",
    "\n",
    "    # Create DataFrame with both counts and percentages\n",
    "    value_counts_df = pd.DataFrame(\n",
    "        {\"count\": value_counts, column: value_counts.index, \"percentage\": percentages}\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    ax = sns.barplot(\n",
    "        data=value_counts_df,\n",
    "        x=\"count\",\n",
    "        y=column,\n",
    "        hue=column,\n",
    "        orient=\"h\",\n",
    "        order=value_counts_df[column],\n",
    "        palette=[color for _ in range(len(value_counts_df))],\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "    # Add labels with count and optionally percentage\n",
    "    for i, v in enumerate(value_counts_df[\"count\"]):\n",
    "        if show_percentages:\n",
    "            label = f\"{int(v)} ({percentages[i]:.1f}%)\"\n",
    "        else:\n",
    "            label = f\"{int(v)}\"\n",
    "        ax.text(v + 5, i, label, va=\"center\")  # padding\n",
    "\n",
    "    # Extend x-axis to accommodate labels\n",
    "    max_val = value_counts_df[\"count\"].max()\n",
    "    ax.set_xlim(0, max_val * extra_space)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Quantidade\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "01530e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_barh_plot(df, \"natureza\", \"Natureza dos projetos\", palette[0], extra_space=1.18)\n",
    "\n",
    "make_barh_plot(df, \"situacao\", \"Situação dos projetos\", palette[1], extra_space=1.14)\n",
    "\n",
    "make_barh_plot(df, \"especie\", \"Espécies de projetos\", palette[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01530e31",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Resumo das variáveis categóricas:\n",
    "\n",
    "-   **BIM**: Apenas 3.5% dos projetos usou BIM, enquanto 66.2% não usou.\n",
    "-   **Natureza dos projetos**: A grande maioria dos itens (73%) é classificado como obra, e não como projeto ou projeto de investimento em infraestrutura.\n",
    "-   **Situação dos projetos**: 76% projetos estão cadastrados, com 11% em execução, 8% concluídos e 3% inativados, cancelados, paralisados ou inacabados.\n",
    "-   **Espécies de projetos**: 44% construção de novos projetos e 54% reforma, ampliação ou recuperação de projetos existentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08873e05",
   "metadata": {},
   "source": [
    "#### 3.3.2 Variáveis quantitativas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "08873e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = len(df[\"qdtEmpregosGerados\"])\n",
    "nans = df[\"qdtEmpregosGerados\"].isna().sum()\n",
    "print(f\"NaN percentage for qdtEmpregosGerados: {nans/count*100:.1f}%\")\n",
    "\n",
    "count = len(df[\"populacaoBeneficiada\"])\n",
    "nans = df[\"populacaoBeneficiada\"].isna().sum()\n",
    "print(f\"NaN percentage for populacaoBeneficiada: {nans/count*100:.1f}%\")\n",
    "\n",
    "both_nan = df[df[\"qdtEmpregosGerados\"].isna() & df[\"populacaoBeneficiada\"].isna()]\n",
    "print(f\"Number of rows where both values are NaN: {len(both_nan)/len(df)*100:.1f}%\")\n",
    "print()\n",
    "print(\n",
    "    f'Non-nan values in both columns: {len(df[df[\"qdtEmpregosGerados\"].notna() & df[\"populacaoBeneficiada\"].notna()])}'\n",
    ")\n",
    "print(\n",
    "    f'Non-nan values in qdtEmpregosGerados: {len(df[df[\"qdtEmpregosGerados\"].notna()])}'\n",
    ")\n",
    "print(\n",
    "    f'Non-nan values in populacaoBeneficiada: {len(df[df[\"populacaoBeneficiada\"].notna()])}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "08873e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quant_df = df[df[\"qdtEmpregosGerados\"].notna() & df[\"populacaoBeneficiada\"].notna()]\n",
    "\n",
    "# make_barh_plot(\n",
    "#     quant_df, \"natureza\", \"Natureza dos projetos\", palette[0], show_percentages=False\n",
    "# )\n",
    "\n",
    "# make_barh_plot(\n",
    "#     quant_df, \"situacao\", \"Situacao de projetos\", palette[1], show_percentages=False\n",
    "# )\n",
    "\n",
    "# make_barh_plot(\n",
    "#     quant_df, \"especie\", \"Especies de projetos\", palette[2], show_percentages=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca743a",
   "metadata": {},
   "source": [
    "Devemos considerar que estes dados estão faltando em 95% dos registros. Apesar disso, os 5% dos projetos com dados quantitativos parecem possuir a mesma distribuição da amostra geral (conferme célula anterior, removida por simplicidade) -- não são apenas projetos em execução/concluídos, como eu imaginava. Portanto, isso sugere que é uma questão de problemas de coleta de dados, e não de que esses dados só existem quando um projeto é executado ou concluído.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "d32ac31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swarm plot escolhido em vez de histograma pois só há 35 observações\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.swarmplot(data=df, x=\"qdtEmpregosGerados\", size=8, color=palette[0])\n",
    "plt.title(\"Quantidade de Empregos Gerados\")\n",
    "plt.xlabel(\"Empregos Gerados\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "a7df8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier de empregos gerados\n",
    "df[[\"idUnico\", \"nome\", \"descricao\", \"qdtEmpregosGerados\"]].sort_values(\n",
    "    by=\"qdtEmpregosGerados\", ascending=False\n",
    ").head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "a7df8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pq tem 8 projetos com exatamente 50 empregos gerados?\n",
    "qtd_mode = df[\"qdtEmpregosGerados\"].mode().values[0]\n",
    "print(f\"Mode value: {qtd_mode}\")\n",
    "print(\n",
    "    f\"Number of projects with mode value: {len(df[df['qdtEmpregosGerados'] == qtd_mode])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "0cc74df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "sns.swarmplot(data=df, x=\"populacaoBeneficiada\", size=8, color=palette[1])\n",
    "plt.title(\"População Beneficiada\")\n",
    "plt.xlabel(\"População Beneficiada\")\n",
    "plt.ylabel(\"Projetos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "0cc74df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribuição melhor visualizada com escala logaritmica\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.swarmplot(\n",
    "    data=df, x=\"populacaoBeneficiada\", size=8, color=palette[1], log_scale=True\n",
    ")\n",
    "plt.title(\"População Beneficiada (escala logarítmica)\")\n",
    "plt.xlabel(\"População Beneficiada (log)\")\n",
    "plt.ylabel(\"Projetos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "32c91161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers de população beneficiada\n",
    "df[[\"idUnico\", \"nome\", \"populacaoBeneficiada\"]].sort_values(\n",
    "    by=\"populacaoBeneficiada\", ascending=False\n",
    ").head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c91161",
   "metadata": {},
   "source": [
    "##### Investimento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "6b471ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normal scale\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(\n",
    "    data=df[~df[\"isInvestimentoSimbolico\"]],\n",
    "    x=\"investimentoTotal\",\n",
    "    bins=25,\n",
    "    color=palette[0],\n",
    ")\n",
    "plt.xlabel(\"Faixa de Investimento (R$)\")\n",
    "plt.ylabel(\"Projetos\")\n",
    "plt.title(\"Projetos por Investimento\")\n",
    "\n",
    "# Plot log scale\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(\n",
    "    data=df[~df[\"isInvestimentoSimbolico\"]],\n",
    "    x=\"investimentoTotal\",\n",
    "    bins=25,\n",
    "    color=palette[0],\n",
    "    log_scale=True,\n",
    ")\n",
    "plt.xlabel(\"Faixa de Investimento (R$)\")\n",
    "plt.ylabel(\"Projetos\")\n",
    "plt.title(\"Projetos por Investimento (escala logarítmica)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "bfa6226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df[\"isInvestimentoSimbolico\"]][\"investimentoTotal\"].describe().apply(\n",
    "    lambda x: f\"{x:,.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "b99c2597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iqr(data: pd.Series) -> float:\n",
    "    q75 = data.quantile(0.75)\n",
    "    q25 = data.quantile(0.25)\n",
    "    return q75 - q25\n",
    "\n",
    "\n",
    "valores = df[~df[\"isInvestimentoSimbolico\"]][\"investimentoTotal\"]\n",
    "iqr = calculate_iqr(valores)\n",
    "print(f\"IQR: R$ {iqr:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba652ada",
   "metadata": {},
   "source": [
    "Após selecionar apenas of projetos com investimentos significativos, vemos uma distribuição aproximadamente log-normal (comum com este tipo de dado não-negativo, como dinheiro). Isso significa que grandes investimento são exponencialmente mais raros que os casos de investimento menor.\n",
    "\n",
    "Isso também significa que a média é pouco informativa sobre os dados; podemos usar mediana e IQR para ter uma ideia melhor\n",
    "\n",
    "Ela apresenta, aproximadamente:\n",
    "\n",
    "-   Variação entre 4 mil e 800 milhões\n",
    "-   Mediana (valor que divide os dados ao meio): 2 milhões\n",
    "-   IQR (amplitude interquartil): 8 milhões\n",
    "-   Cerca de 50% dos projetos entre 1 e 8 milhões.\n",
    "\n",
    "Assim, isso também indica que os valores mais altos não são outliers, mas são parte da distribuição log-normal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "aac8d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores altos\n",
    "df[[\"descricao\", \"investimentoTotal\"]].sort_values(\n",
    "    by=\"investimentoTotal\", ascending=False\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3b16c",
   "metadata": {},
   "source": [
    "Várias creches parecem receber investimentos com valor simbólico.\n",
    "\n",
    "Valores mais altos de investimento incluem:\n",
    "\n",
    "-   SISFRON (Sistema Integrado de Monitoramento de Fronteiras): R$ 840 milhões\n",
    "-   Obras rodoviárias R$ 596, R$ 359, R$ 353 milhões\n",
    "-   Asessoramentos diversos: 193, 119, 112 milhões\n",
    "-   Instalação de Estações Metereológicas: 118 milhões\n",
    "\n",
    "Como só há 5% de não-nulos nas outras categorias quantitativas, opto por não calcular correlação e etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "aac8d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores baixos simbólicos\n",
    "df[[\"nome\", \"investimentoTotal\"]].sort_values(\n",
    "    by=\"investimentoTotal\", ascending=True\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "b3e6518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores baixos não-simbólicos\n",
    "df[~df[\"isInvestimentoSimbolico\"]][[\"nome\", \"investimentoTotal\"]].sort_values(\n",
    "    by=\"investimentoTotal\", ascending=True\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df991b9",
   "metadata": {},
   "source": [
    "### Datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "1170e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = [\n",
    "    \"dataInicialPrevista\",\n",
    "    \"dataFinalPrevista\",\n",
    "    \"dataInicialEfetiva\",\n",
    "    \"dataFinalEfetiva\",\n",
    "    \"dataCadastro\",\n",
    "    \"dataSituacao\",\n",
    "]\n",
    "\n",
    "df[date_cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "a7d1947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normal scale\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(\n",
    "    data=df[\"duracaoPrevista\"].value_counts().reset_index(),\n",
    "    bins=50,\n",
    "    color=palette[0],\n",
    ")\n",
    "plt.xlabel(\"Duração Prevista (dias)\")\n",
    "plt.ylabel(\"Projetos\")\n",
    "plt.title(\"Projetos por Duração Prevista\")\n",
    "\n",
    "# Plot log scale\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(\n",
    "    data=df[\"duracaoPrevista\"].value_counts().reset_index(),\n",
    "    bins=50,\n",
    "    color=palette[0],\n",
    "    log_scale=True,\n",
    ")\n",
    "plt.xlabel(\"Duração Prevista (dias)\")\n",
    "plt.ylabel(\"Projetos\")\n",
    "plt.title(\"Projetos por Duração Prevista (escala logarítmica)\")\n",
    "\n",
    "# Plot log-log scale\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.scatterplot(\n",
    "    data=df[\"duracaoPrevista\"].value_counts().reset_index(), alpha=0.5, color=palette[0]\n",
    ")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Duração Prevista (dias)\")\n",
    "plt.ylabel(\"Número de Projetos\")\n",
    "plt.title(\"Projetos por Duração Prevista (escala log-log)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "62da087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_counts = df[\"duracaoPrevista\"].dt.days.value_counts().head(5)\n",
    "for days, count in duration_counts.items():\n",
    "    print(f\"{days} days ({days/365:.2f} years): {count} projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "4a576691",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"duracaoPrevista\"].dt.days.divide(365).describe().apply(lambda x: f\"{x:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "b4a23bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IQR:\", calculate_iqr(df[\"duracaoPrevista\"].dt.days.divide(365)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47671043",
   "metadata": {},
   "source": [
    "Nesse caso, parece ser uma distribuição power-law (observada como linha aproximadamente reta no gráfico log-log). Isso significa que (ainda mais do que os investimentos) a grande maioria dos projetos possui duração curta, e alguns duração extremamente longa.\n",
    "\n",
    "Assim, é difícil dizer que haja um caso que caia 'fora da curva', pois não há um caso padrão como haveria numa distribuição normal.\n",
    "\n",
    "Dito disso, não é incomum que projetos sejam declarados com duração exata de 1, 2, 3, 4, ou 5 anos, conforme indicado na aparente 'quantização' dos valores. Há alguns projetos declarados com duração de 364 dias em vez de 365\n",
    "\n",
    "-   valor mínimo de 0 dias\n",
    "-   valor máximo de 13 anos\n",
    "-   mediana: 1.2 anos\n",
    "-   IQR de 2.18 anos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "7c08366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores altos\n",
    "df[[\"descricao\", \"duracaoPrevista\", \"investimentoFaixa\"]].sort_values(\n",
    "    by=\"duracaoPrevista\", ascending=False\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "7a91338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores baixos\n",
    "df[[\"descricao\", \"duracaoPrevista\", \"investimentoFaixa\"]].sort_values(\n",
    "    by=\"duracaoPrevista\", ascending=True\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a856b",
   "metadata": {},
   "source": [
    "anomalias: projetos com investimento entre 1 e 10 milhões com duração prevista de zero dias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "8bee3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dataInicialPrevista is in the future\n",
    "future_starts = df[df[\"dataInicialPrevista\"] > pd.Timestamp.now()]\n",
    "print(f\"Number of projects with start date in the future: {len(future_starts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d598c5",
   "metadata": {},
   "source": [
    "Devido à falta de dados para as datas reais, podemos comparar apenas as datas previstas.\n",
    "\n",
    "Apesar de apenas 81 (11%) projetos estarem em situação 'em execução', apenas 4 projetos possuem início no futuro -- com a maioria em situação de 'cadastrado'. A documentação dos dados não entra em detalhes sobre o significado destas categorias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "f933965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for date distributions\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12), sharex=True)\n",
    "\n",
    "ax1.hist(df[\"dataInicialPrevista\"].dropna(), bins=50)\n",
    "ax1.set_title(\"Distribuição das Datas Iniciais Previstas\")\n",
    "ax1.set_ylabel(\"Frequência\")\n",
    "\n",
    "ax2.hist(df[\"dataFinalPrevista\"].dropna(), bins=50)\n",
    "ax2.set_title(\"Distribuição das Datas Finais Previstas\")\n",
    "ax2.set_xlabel(\"Data\")\n",
    "ax2.set_ylabel(\"Frequência\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4dd427",
   "metadata": {},
   "source": [
    "Houve um pico de projetos entre 2012 e 2016. Conforme esperado, a maior parte termina me menos de 2 anos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "97b4f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check big and small date values\n",
    "df[[\"descricao\", \"dataFinalPrevista\"]].sort_values(\n",
    "    by=\"dataFinalPrevista\", ascending=False\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "ef8ab232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check big and small date values\n",
    "df[[\"descricao\", \"dataFinalPrevista\"]].sort_values(\n",
    "    by=\"dataFinalPrevista\", ascending=True\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "8871a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check big and small date values\n",
    "df[[\"descricao\", \"dataInicialPrevista\"]].sort_values(\n",
    "    by=\"dataInicialPrevista\", ascending=False\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "78fe2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check big and small date values\n",
    "df[[\"descricao\", \"dataInicialPrevista\"]].sort_values(\n",
    "    by=\"dataInicialPrevista\", ascending=True\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "3c92dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados\n",
    "data_for_reg = df[~df[\"isInvestimentoSimbolico\"]].copy()\n",
    "data_for_reg = data_for_reg[\n",
    "    [\"idUnico\", \"descricao\", \"duracaoPrevista\", \"investimentoTotal\"]\n",
    "].dropna()\n",
    "data_for_reg[\"duracaoPrevista_days\"] = data_for_reg[\"duracaoPrevista\"].dt.days.astype(\n",
    "    int\n",
    ")\n",
    "\n",
    "# Transformações apropriadas para cada distribuição\n",
    "data_for_reg[\"investimentoTotal_log\"] = np.log(\n",
    "    data_for_reg[\"investimentoTotal\"]\n",
    ")  # Log-normal\n",
    "data_for_reg[\"duracaoPrevista_log\"] = np.log(\n",
    "    data_for_reg[\"duracaoPrevista_days\"]\n",
    ")  # Power-law também usa log\n",
    "\n",
    "# Criar figura com múltiplos subplots para comparação\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "# 1. Escala original (não recomendado, mas para referência)\n",
    "sns.regplot(\n",
    "    data=data_for_reg,\n",
    "    x=\"duracaoPrevista_days\",\n",
    "    y=\"investimentoTotal\",\n",
    "    scatter_kws={\"alpha\": 0.5},\n",
    "    line_kws={\"color\": \"red\"},\n",
    "    ax=axes[0],\n",
    ")\n",
    "axes[0].set_title(\"Escala Original (não ideal)\")\n",
    "axes[0].set_xlabel(\"Duração Prevista (dias)\")\n",
    "axes[0].set_ylabel(\"Investimento Total (R$)\")\n",
    "\n",
    "# 2. Log-log (melhor para capturar ambas as distribuições)\n",
    "sns.regplot(\n",
    "    data=data_for_reg,\n",
    "    x=\"duracaoPrevista_log\",\n",
    "    y=\"investimentoTotal_log\",\n",
    "    scatter_kws={\"alpha\": 0.5},\n",
    "    line_kws={\"color\": \"red\"},\n",
    "    ax=axes[1],\n",
    ")\n",
    "axes[1].set_title(\"Log-Log (RECOMENDADO)\")\n",
    "axes[1].set_xlabel(\"Log da Duração Prevista (dias)\")\n",
    "axes[1].set_ylabel(\"Log do Investimento Total (R$)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "98a2806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_corr = df[~df[\"isInvestimentoSimbolico\"]].copy()\n",
    "data_for_corr = data_for_corr[[\"duracaoPrevista\", \"investimentoTotal\"]].dropna()\n",
    "data_for_corr[\"duracaoPrevista_days\"] = data_for_corr[\"duracaoPrevista\"].dt.days.astype(\n",
    "    int\n",
    ")\n",
    "\n",
    "\n",
    "pg.corr(\n",
    "    data_for_corr[\"duracaoPrevista_days\"],\n",
    "    data_for_corr[\"investimentoTotal\"],\n",
    "    method=\"spearman\",  # nao parametrico\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "8588f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_reg = data_for_reg.replace([np.inf, -np.inf], np.nan)\n",
    "data_for_reg = data_for_reg.dropna()\n",
    "\n",
    "X = sm.add_constant(data_for_reg[\"duracaoPrevista_log\"])\n",
    "y = data_for_reg[\"investimentoTotal_log\"]\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "data_for_reg[\"residuos\"] = model.resid\n",
    "data_for_reg[\"residuos_abs\"] = np.abs(model.resid)\n",
    "\n",
    "data_for_reg.nlargest(10, \"residuos_abs\").assign(\n",
    "    duracaoPrevista_years=lambda x: x[\"duracaoPrevista_days\"] / 365,\n",
    "    investimentoTotal_k=lambda x: x[\"investimentoTotal\"].apply(lambda x: f\"{x:,.2f}\"),\n",
    ")[\n",
    "    [\"idUnico\", \"descricao\", \"duracaoPrevista_years\", \"investimentoTotal_k\", \"residuos\"]\n",
    "].round(\n",
    "    {\"duracaoPrevista_years\": 1, \"investimentoTotal_k\": 0, \"residuos\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f3361",
   "metadata": {},
   "source": [
    "Considerando apenas os projetos com investimento significativo, podemos ver que há uma correlação entre a duração prevista e o investimento total (spearman = 0.64). Isso é esperado, pois projetos maiores tendem a durar mais. Mas com esses dados podemos calcular os projetos mais anômalos: curtos que custam muito ou demorados que custam pouco. Isso é feito usando os residuos de uma regressão linear. Com isso encontramos os itens mais anômalos, enumerados acima\n",
    "\n",
    "Com tudo isso, encontramos os registros mais anômalos:\n",
    "\n",
    "| ID          | Descrição                                         | Duração  | Investimento      |\n",
    "| ----------- | ------------------------------------------------- | -------- | ----------------- |\n",
    "| 46882.53-02 | CONSTRUÇÃO DE UNIDADE DE ATENÇÃO ESPECIALIZADA... | 1 dia    | R$ 2.493.000,00   |\n",
    "| 43724.53-06 | Contratação de empresa do ramo de engenharia/a... | 3 anos   | R$ 4.684,45       |\n",
    "| 557.53-69   | Projeto Estratégico do SISFRON...                 | 1.6 anos | R$ 839.664.954,32 |\n",
    "| 10613.53-07 | Prestação de serviços de disponibilização de a... | 4.9 anos | R$ 47.700,00      |\n",
    "| 5223.53-75  | ELABORAÇÃO DE PROJETOS BÁSICO E EXECUTIVO DE P... | 2.2 anos | R$ 20.305,41      |\n",
    "| 39020.52-43 | execução das obras de adequação de capacidade,... | 1.7 anos | R$ 352.994.609,29 |\n",
    "| 28451.53-40 | ADEQUACAO DE TRECHO RODOVIARIO - ENTRONCAMENTO... | 2.1 anos | R$ 359.130.057,13 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d510a8",
   "metadata": {},
   "source": [
    "### NLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c03a4",
   "metadata": {},
   "source": [
    "Podemos usar as colunas que contem texto para analisar padrões semânticos nos dados. Aqui, usamos embeddings com redução de dimensionalidade e clusterização.\n",
    "\n",
    "Como o dataset é pequeno, uma outra alternativa seria concatenar todos os textos e usar uma LLM para fazer análises diversas. Mas não implemente isso.\n",
    "\n",
    "O modelo de embedding se beneficia de ser usado em um computador com GPU. Assim, as células seguintes estão comentadas. A produção dos embeddings foi feita na nuvem e salvos em um arquivo que é aberto aqui.\n",
    "\n",
    "Poderíamos continuar automatizando isso com uma abordagem como a do BERTopic, fazendo topic modelling e usando LLMs para nomear os tópicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "d4fee7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['idUnico', 'textoTotal']].to_parquet('data/projetos_sem_vetores.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "260024c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fazer isso aqui usando uma GPU - por exemplo, no google colab\n",
    "\n",
    "\n",
    "# def get_embeddings(df: pd.DataFrame, model: SentenceTransformer) -> pd.DataFrame:\n",
    "#     # https://huggingface.co/google/embeddinggemma-300m\n",
    "\n",
    "#     # requires HF_TOKEN env variable\n",
    "#     from dotenv import load_dotenv\n",
    "#     load_dotenv()\n",
    "\n",
    "\n",
    "#     # gated model: only unlocks if you sign the terms and conditions consent form in the huggingface model page\n",
    "#     from sentence_transformers import SentenceTransformer\n",
    "#     model = SentenceTransformer(\"google/embeddinggemma-300m\")\n",
    "\n",
    "#     sentences = df[\"textoTotal\"].tolist()\n",
    "\n",
    "#     embeddings = model.encode(\n",
    "#         sentences=sentences,\n",
    "#         prompt_name=\"Clustering\", # gemma specific\n",
    "#         show_progress_bar=True,\n",
    "#         convert_to_numpy=True,\n",
    "#     )\n",
    "\n",
    "#     sentences_with_embeddings = pd.DataFrame(\n",
    "#         {\"texto\": sentences, \"embeddings\": embeddings.tolist()}\n",
    "#     )\n",
    "#     df_with_embeddings = pd.merge(\n",
    "#         df, sentences_with_embeddings, left_on=\"textoTotal\", right_on=\"texto\"\n",
    "#     )\n",
    "#     df_with_embeddings = df_with_embeddings.drop(\"texto\", axis=1)\n",
    "#     return df_with_embeddings\n",
    "\n",
    "\n",
    "# textos_df = pd.read_parquet('data/projetos_sem_vetores.parquet')\n",
    "# df_with_embeddings = get_embeddings(textos_df, model)\n",
    "# df_with_embeddings.to_parquet('data/projetos_com_vetores.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "b0b2f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_parquet(\"data/projetos_com_vetores.parquet\")\n",
    "df = df.merge(embeddings.drop(\"textoTotal\", axis=1), on=\"idUnico\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "b3a17966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_df(\n",
    "    df: pd.DataFrame, vectors_col: str, dimension_names: list[str]\n",
    ") -> pd.DataFrame:\n",
    "    # Based on https://umap-learn.readthedocs.io/en/latest/\n",
    "\n",
    "    reducer = umap.UMAP(\n",
    "        n_components=2,\n",
    "        n_neighbors=15,  # Default from documentation\n",
    "        min_dist=0.1,  # Default from documentation\n",
    "        metric=\"euclidean\",  # Default metric\n",
    "        random_state=42,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    umap_components = reducer.fit_transform(df[vectors_col].tolist())\n",
    "    umap_df = pd.DataFrame(umap_components, columns=dimension_names)  # type: ignore\n",
    "    return pd.concat([df, umap_df], axis=1)\n",
    "\n",
    "\n",
    "def hdbscan_df(\n",
    "    df: pd.DataFrame, dimension_names: list[str], min_cluster_size: int\n",
    ") -> pd.DataFrame:\n",
    "    # https://github.com/scikit-learn-contrib/hdbscan\n",
    "\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size)\n",
    "    clusters = clusterer.fit_predict(df[dimension_names])\n",
    "    df[\"cluster\"] = clusters\n",
    "    df[\"cluster\"] = df[\"cluster\"].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_embeddings(df: pd.DataFrame, dimension_names: list[str], hue: str) -> None:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=df,\n",
    "        x=dimension_names[0],\n",
    "        y=dimension_names[1],\n",
    "        hue=hue,\n",
    "        palette=\"tab10\",\n",
    "        s=100,  # marker size\n",
    "        alpha=0.7,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "\n",
    "    plt.title(\"UMAP Projection of Project Embeddings\", fontsize=16, pad=20)\n",
    "    plt.xlabel(\"UMAP Dimension 1\", fontsize=12)\n",
    "    plt.ylabel(\"UMAP Dimension 2\", fontsize=12)\n",
    "    plt.legend(title=\"Cluster\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_embeddings_interactive(\n",
    "    df: pd.DataFrame, dimension_names: list[str], hue: str\n",
    ") -> alt.Chart:\n",
    "    chart = (\n",
    "        alt.Chart(df)\n",
    "        .mark_circle(size=100, opacity=0.7, strokeWidth=0.5, stroke=\"white\")\n",
    "        .encode(\n",
    "            x=alt.X(dimension_names[0], title=\"UMAP1\"),\n",
    "            y=alt.Y(dimension_names[1], title=\"UMAP2\"),\n",
    "            color=alt.Color(\n",
    "                hue,\n",
    "                scale=alt.Scale(scheme=\"tableau10\"),\n",
    "                legend=alt.Legend(title=\"Cluster\"),\n",
    "            ),\n",
    "            tooltip=[hue],\n",
    "        )\n",
    "        .properties(\n",
    "            width=600, height=500, title=\"UMAP Projection of Project Embeddings\"\n",
    "        )\n",
    "        .interactive()\n",
    "    )  # Enables pan and zoom\n",
    "\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a28936",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_names = [\"UMAP_1\", \"UMAP_2\"]\n",
    "\n",
    "df_nlp_vis = df.copy()\n",
    "df_nlp_vis = df_nlp_vis[\"duracaoPrevista\"].dt.days  # altair breaks otherwise\n",
    "df_nlp_vis = umap_df(df_nlp_vis, \"embeddings\", dimension_names)\n",
    "df_nlp_vis = hdbscan_df(df_nlp_vis, dimension_names, min_cluster_size=20)\n",
    "# plot_embeddings(df_nlp_vis, dimension_names, hue=\"cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "58a28936",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings_interactive(df_nlp_vis, dimension_names, hue=\"cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e0b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print examples from each cluster\n",
    "print(\"\\nExample projects from each cluster:\")\n",
    "for cluster in sorted(df_nlp_vis[\"cluster\"].unique()):\n",
    "    cluster_df = df_nlp_vis[df_nlp_vis[\"cluster\"] == cluster].copy()\n",
    "    print(f\"\\nCluster {cluster}:\")\n",
    "    # Show 3 random examples from each cluster\n",
    "    examples = cluster_df.sample(n=min(3, len(cluster_df)))\n",
    "    for _, row in examples.iterrows():\n",
    "        print(f\"- {row['idUnico']} - {row['nome']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7270dd3e",
   "metadata": {},
   "source": [
    "Vemos aqui algumas das categorias que descobrimos ao analisar o texto usando embeddings. Como o gráfico é interativo, é possível clicar nos itens e investigar. No entanto, apenas olhando para os títulos de alguns exemplares, conforme a célula acima, podemos apreender algumas coisas, como:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb23669",
   "metadata": {},
   "source": [
    "### GIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4d6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(df)\n",
    "missing = df[\"cep\"].isna().sum()\n",
    "print(f\"Missing CEP values: {missing} out of {total} ({missing/total:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geocode_ceps import cep_to_coords_viacep, cep_to_coords_ipedf\n",
    "\n",
    "ceps = df[\"cep\"].dropna().unique()\n",
    "\n",
    "# non-idempotent\n",
    "# cep_to_coords_viacep(ceps.tolist(), \"data/cep_coords_viacep.json\")\n",
    "# cep_to_coords_ipedf(ceps.tolist(), \"data/cep_coords_ipedf.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfae94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoids pandas assuming cep is a date\n",
    "with open(\"data/cep_coords_viacep.json\") as f:\n",
    "    data = json.load(f)\n",
    "df_viacep = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "df_viacep.columns = [\"latitude\", \"longitude\"]\n",
    "print(\n",
    "    f\"Null records: {df_viacep['latitude'].isna().sum()} out of {len(df_viacep)} ({df_viacep['latitude'].isna().sum()/len(df_viacep):.1%})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d280dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoids pandas assuming cep is a date\n",
    "with open(\"data/cep_coords_ipedf.json\") as f:\n",
    "    data = json.load(f)\n",
    "df_ipedf = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "df_ipedf.columns = [\"latitude\", \"longitude\"]\n",
    "print(\n",
    "    f\"Null records: {df_ipedf['latitude'].isna().sum()} out of {len(df_ipedf)} ({df_ipedf['latitude'].isna().sum()/len(df_ipedf):.1%})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(\n",
    "    df_viacep, left_on=\"cep\", right_index=True, how=\"left\", suffixes=(\"\", \"_viacep\")\n",
    ")\n",
    "\n",
    "df = df.merge(\n",
    "    df_ipedf, left_on=\"cep\", right_index=True, how=\"left\", suffixes=(\"\", \"_ipedf\")\n",
    ")\n",
    "\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"latitude\": \"lat_viacep\",\n",
    "        \"longitude\": \"lon_viacep\",\n",
    "        \"latitude_ipedf\": \"lat_ipedf\",\n",
    "        \"longitude_ipedf\": \"lon_ipedf\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Records with coordinates from both sources: {df[['lon_viacep', 'lon_ipedf']].notna().all(axis=1).sum()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count records with and without coordinates\n",
    "has_viacep = df[[\"lat_viacep\", \"lon_viacep\"]].notna().all(axis=1)\n",
    "has_ipedf = df[[\"lat_ipedf\", \"lon_ipedf\"]].notna().all(axis=1)\n",
    "\n",
    "print(\n",
    "    f\"Records with coordinates from either source: {(has_viacep | has_ipedf).sum()} ({(has_viacep | has_ipedf).sum()/len(df):.1%})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b35c5",
   "metadata": {},
   "source": [
    "Usando APIs oficiais do governo, elas parecem ter dificuldade de usar os CEPs para obter as coordenadas dos locais. Ambos os metodos só encontraram cerca de metade dos 88 CEPs presentes dos dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668594e7",
   "metadata": {},
   "source": [
    "Apenas 18% de todos os registros possui representação neste mapa. Esta amostra representa algum tipo de viés de seleção -- primeiro dos registros com CEP e depois dos CEPs com coordenadas. Dos 88 CEPs válidos, as ferramentas de geocodificação do governo só encontraram coordenadas para 41 e 33, respectivamente; 29 foram encontrados por ambas -- o que não significa que eles encontraram as mesmas coordenadas (e.g., CEP CEP 71205050).\n",
    "\n",
    "Quando tem duas coordenadas foi optado pelas do IPEDF por obter o CEP direto, enquanto o ViaCEP apenas converte em endereço, que é convertido em coordenadas via Nominatim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668594e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Create map centered on DF\n",
    "m = folium.Map(location=[-15.7942, -47.8822], zoom_start=10)\n",
    "\n",
    "# Define single color for all markers\n",
    "COLOR = \"#412355\"  # Purple (LabLivre palette)\n",
    "\n",
    "# Prepare data with proper coordinate selection\n",
    "df_map = df[\n",
    "    [\n",
    "        \"cep\",\n",
    "        \"nome\",\n",
    "        \"descricao\",\n",
    "        \"lat_ipedf\",\n",
    "        \"lon_ipedf\",\n",
    "        \"lat_viacep\",\n",
    "        \"lon_viacep\",\n",
    "        \"investimentoTotal\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Add markers for each project with coordinates\n",
    "for idx, row in df_map.iterrows():\n",
    "    lat_ipedf = row[\"lat_ipedf\"]\n",
    "    lon_ipedf = row[\"lon_ipedf\"]\n",
    "    lat_viacep = row[\"lat_viacep\"]\n",
    "    lon_viacep = row[\"lon_viacep\"]\n",
    "\n",
    "    # Determine which coordinates to use (prioritize IPEDF)\n",
    "    if pd.notna(lat_ipedf) and pd.notna(lon_ipedf):\n",
    "        lat, lon = lat_ipedf, lon_ipedf\n",
    "        source = \"IPEDF\"\n",
    "    elif pd.notna(lat_viacep) and pd.notna(lon_viacep):\n",
    "        lat, lon = lat_viacep, lon_viacep\n",
    "        source = \"ViaCEP\"\n",
    "    else:\n",
    "        # No coordinates available\n",
    "        continue\n",
    "\n",
    "    # Prepare popup text\n",
    "    popup_text = (\n",
    "        f\"\"\"\n",
    "    <b>CEP:</b> {row['cep']}<br>\n",
    "    <b>Fonte:</b> {source}<br>\n",
    "    <b>Nome:</b> {row['nome'][:50]}...<br>\n",
    "    <b>Investimento:</b> R$ {row['investimentoTotal']:,.2f}\n",
    "    \"\"\"\n",
    "        if pd.notna(row[\"investimentoTotal\"])\n",
    "        else f\"\"\"\n",
    "    <b>CEP:</b> {row['cep']}<br>\n",
    "    <b>Fonte:</b> {source}<br>\n",
    "    <b>Nome:</b> {row['nome'][:50]}...\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    # Add marker with radius scaled by investment amount\n",
    "    folium.CircleMarker(\n",
    "        location=[lat, lon],\n",
    "        radius=(\n",
    "            np.sqrt(row[\"investimentoTotal\"] / 100000)\n",
    "            if pd.notna(row[\"investimentoTotal\"])\n",
    "            else 5\n",
    "        ),\n",
    "        color=COLOR,\n",
    "        fill=True,\n",
    "        fillColor=COLOR,\n",
    "        fillOpacity=0.7,\n",
    "        popup=folium.Popup(popup_text, max_width=300),\n",
    "        tooltip=f\"{row['cep']} - {source}\",\n",
    "    ).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668594e7",
   "metadata": {},
   "source": [
    "Podemos ver uma concentração de investimentos na área da asa sul. Há investimentos em ceilandia, gama, planaltina. de resto, há poucos ou nenhum (e.g. são sebastião).\n",
    "\n",
    "Parte da ausência no mapa pode ser devido ao processo de seleção dos dados ou a disponibilidade dos CEPs nas APIs de geocoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab4d6d5",
   "metadata": {},
   "source": [
    "## Relatório\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba026fc",
   "metadata": {},
   "source": [
    "Vários campos tem problema sistemáticos. Talvez o formulário seja confuso, talvez falte masking, talvez o campo não se aplique a um projeto. Isso precisaria ser investigado melhor. Para detalhes, ver seção `3.2 Qualidade`.\n",
    "\n",
    "Em termos de\n",
    "\n",
    "Os investimentos revelaram uma categoria implícita de investimento simbólico.\n",
    "\n",
    "Atenção aos maiores investimentos também é relevante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e0cf04",
   "metadata": {},
   "source": [
    "## Conclusão\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
